# Unreal ê²Œì„ QA ìë™í™” ì‹œìŠ¤í…œ ëª…ì„¸ì„œ (Windows IDE í™˜ê²½)

## ê°œìš”

Windows IDE í™˜ê²½ì—ì„œ ì§ì ‘ ì‹¤í–‰í•˜ëŠ” ê²Œì„ QA ìë™í™” ì‹œìŠ¤í…œ

**í•µì‹¬ ê°œì„ ì‚¬í•­:**
- âœ… WSL ê²½ìœ  ì—†ì´ ìˆœìˆ˜ Windows í™˜ê²½ì—ì„œ ì‹¤í–‰
- âœ… ë¡œì»¬ OCR (PaddleOCR/EasyOCR) ì‚¬ìš©ìœ¼ë¡œ API ë¹„ìš© ì ˆê°
- âœ… ì„ íƒì  ë¡œì»¬ Vision LLM (Ollama + LLaVA) ë˜ëŠ” Claude API
- âœ… Streamlit/Gradio ì›¹ UIë¡œ ì‚¬ìš©ì ì¹œí™”ì  ì¸í„°í˜ì´ìŠ¤
- âœ… VS Code/PyCharmì—ì„œ ì§ì ‘ ì‹¤í–‰ ë° ë””ë²„ê¹…
- âœ… Jupyter Notebookìœ¼ë¡œ ì¸í„°ë™í‹°ë¸Œ ê°œë°œ

**ì‹¤í–‰ í™˜ê²½:**
- **Windows 10/11**: ë„¤ì´í‹°ë¸Œ ì‹¤í–‰
- **Python 3.8+**: ë‹¨ì¼ í™˜ê²½
- **IDE**: VS Code, PyCharm, Jupyter Notebook
- **ì„ íƒì  GPU**: CUDA ì§€ì› ì‹œ OCR/LLM ê°€ì†

---

## ì•„í‚¤í…ì²˜ ë¹„êµ

### ê¸°ì¡´ (WSL-Windows í•˜ì´ë¸Œë¦¬ë“œ)
```
WSL (Kiro CLI) â†’ JSON í†µì‹  â†’ Windows (PyAutoGUI)
     â†“                              â†“
AWS Bedrock/Rekognition        ìŠ¤í¬ë¦°ìƒ· ìº¡ì²˜
```

### ê°œì„  (Windows IDE ë„¤ì´í‹°ë¸Œ)
```
Windows Python (ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤)
     â”œâ”€ PyAutoGUI (ê²Œì„ ì œì–´)
     â”œâ”€ ë¡œì»¬ OCR (PaddleOCR/EasyOCR)
     â”œâ”€ ë¡œì»¬ LLM (Ollama + LLaVA) ë˜ëŠ” Claude API
     â””â”€ Streamlit UI (ì›¹ ì¸í„°í˜ì´ìŠ¤)
```

**ì¥ì :**
- ê²½ë¡œ ë³€í™˜ ë¶ˆí•„ìš”
- íŒŒì¼ ë™ê¸°í™” ì§€ì—° ì—†ìŒ
- ë””ë²„ê¹… ìš©ì´
- API ë¹„ìš© ëŒ€í­ ì ˆê° (ë¡œì»¬ OCR ì‚¬ìš© ì‹œ)
- ì˜¤í”„ë¼ì¸ ì‹¤í–‰ ê°€ëŠ¥ (ë¡œì»¬ LLM ì‚¬ìš© ì‹œ)

---

## ê¸°ìˆ  ìŠ¤íƒ ì„ íƒ

### 1. OCR ì—”ì§„ (UI ìš”ì†Œ ê°ì§€)

#### Option A: PaddleOCR (ì¶”ì²œ)
**ì¥ì :**
- ë¬´ë£Œ, ì˜¤í”ˆì†ŒìŠ¤
- 100+ ì–¸ì–´ ì§€ì› (í•œê¸€, ì˜ì–´ ëª¨ë‘ ìš°ìˆ˜)
- GPU ê°€ì† ì§€ì›
- ë°”ìš´ë”© ë°•ìŠ¤ + í…ìŠ¤íŠ¸ + ì‹ ë¢°ë„ ì œê³µ
- AWS Rekognitionê³¼ ìœ ì‚¬í•œ ì¶œë ¥ í˜•ì‹

**ì„¤ì¹˜:**
```bash
pip install paddleocr paddlepaddle
# GPU ë²„ì „ (CUDA 11.2+)
pip install paddlepaddle-gpu
```

**ì‚¬ìš© ì˜ˆì‹œ:**
```python
from paddleocr import PaddleOCR

ocr = PaddleOCR(use_angle_cls=True, lang='en')
result = ocr.ocr('screenshot.png', cls=True)

for line in result[0]:
    bbox = line[0]  # [[x1,y1], [x2,y2], [x3,y3], [x4,y4]]
    text = line[1][0]  # í…ìŠ¤íŠ¸
    confidence = line[1][1]  # ì‹ ë¢°ë„
    
    # ì¤‘ì‹¬ì  ê³„ì‚°
    center_x = sum([p[0] for p in bbox]) / 4
    center_y = sum([p[1] for p in bbox]) / 4
```

**ì„±ëŠ¥:**
- CPU: ~0.5-1ì´ˆ/ì´ë¯¸ì§€
- GPU: ~0.1-0.2ì´ˆ/ì´ë¯¸ì§€
- ë¹„ìš©: $0 (ì™„ì „ ë¬´ë£Œ)

#### Option B: EasyOCR
**ì¥ì :**
- ì‚¬ìš©ì´ ë” ê°„ë‹¨
- 80+ ì–¸ì–´ ì§€ì›
- PyTorch ê¸°ë°˜

**ë‹¨ì :**
- PaddleOCRë³´ë‹¤ ëŠë¦¼
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë†’ìŒ

```python
import easyocr

reader = easyocr.Reader(['en', 'ko'])
result = reader.readtext('screenshot.png')

for bbox, text, confidence in result:
    # bbox: [[x1,y1], [x2,y2], [x3,y3], [x4,y4]]
    pass
```

#### Option C: AWS Rekognition (ê¸°ì¡´)
**ì¥ì :**
- ë†’ì€ ì •í™•ë„
- ê´€ë¦¬ ë¶ˆí•„ìš”

**ë‹¨ì :**
- API ë¹„ìš©: $1.50/1,000 images
- ë„¤íŠ¸ì›Œí¬ ì§€ì—°
- ì˜¤í”„ë¼ì¸ ë¶ˆê°€

**ë¹„êµ ê²°ë¡ :** PaddleOCR ì¶”ì²œ (ë¬´ë£Œ + ë¹ ë¦„ + ì •í™•)

---

### 2. Vision LLM (í™”ë©´ ë¶„ì„ ë° ì˜ì‚¬ê²°ì •)

#### Option A: ë¡œì»¬ LLM - Ollama + LLaVA (ì¶”ì²œ - ê°œë°œ/í…ŒìŠ¤íŠ¸)
**ì¥ì :**
- ì™„ì „ ë¬´ë£Œ
- ì˜¤í”„ë¼ì¸ ì‹¤í–‰
- ë¹ ë¥¸ ì‘ë‹µ (ë¡œì»¬)
- API ì œí•œ ì—†ìŒ

**ì„¤ì¹˜:**
```bash
# Ollama ì„¤ì¹˜ (Windows)
# https://ollama.com/download ì—ì„œ ë‹¤ìš´ë¡œë“œ

# LLaVA ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
ollama pull llava:13b
# ë˜ëŠ” ë” ì‘ì€ ëª¨ë¸
ollama pull llava:7b
```

**ì‚¬ìš© ì˜ˆì‹œ:**
```python
import ollama
import base64

def analyze_screen_local(image_path, question):
    """ë¡œì»¬ LLaVAë¡œ í™”ë©´ ë¶„ì„"""
    
    with open(image_path, 'rb') as f:
        image_data = base64.b64encode(f.read()).decode()
    
    response = ollama.chat(
        model='llava:13b',
        messages=[{
            'role': 'user',
            'content': question,
            'images': [image_path]
        }]
    )
    
    return response['message']['content']

# ì‚¬ìš©
answer = analyze_screen_local(
    'screenshot.png',
    'ì´ í™”ë©´ì—ì„œ ë¡œê·¸ì¸ ë²„íŠ¼ì´ ì–´ë””ì— ìˆë‚˜ìš”?'
)
```

**ì„±ëŠ¥:**
- GPU (RTX 3060): ~2-3ì´ˆ/ì‘ë‹µ
- CPU: ~10-20ì´ˆ/ì‘ë‹µ
- ë¹„ìš©: $0

**í•œê³„:**
- Claude/GPTë³´ë‹¤ ì •í™•ë„ ë‚®ìŒ
- ë³µì¡í•œ ì¶”ë¡  ì•½í•¨
- GPU ë©”ëª¨ë¦¬ í•„ìš” (13B: ~8GB, 7B: ~4GB)

#### Option B: Claude API via Bedrock (ì¶”ì²œ - í”„ë¡œë•ì…˜)
**ì¥ì :**
- ìµœê³  ì •í™•ë„
- ë³µì¡í•œ ì¶”ë¡  ê°€ëŠ¥
- ì•ˆì •ì 

**ë‹¨ì :**
- API ë¹„ìš©
- ë„¤íŠ¸ì›Œí¬ í•„ìš”

```python
import boto3
import json
import base64

bedrock = boto3.client('bedrock-runtime', region_name='ap-northeast-2')

def analyze_screen_claude(image_path, question):
    """Claudeë¡œ í™”ë©´ ë¶„ì„"""
    
    with open(image_path, 'rb') as f:
        image_data = base64.b64encode(f.read()).decode()
    
    body = json.dumps({
        "anthropic_version": "bedrock-2023-05-31",
        "max_tokens": 1000,
        "messages": [{
            "role": "user",
            "content": [
                {"type": "image", "source": {"type": "base64", "media_type": "image/png", "data": image_data}},
                {"type": "text", "text": question}
            ]
        }]
    })
    
    response = bedrock.invoke_model(
        modelId='anthropic.claude-3-5-sonnet-20241022-v2:0',
        body=body
    )
    
    result = json.loads(response['body'].read())
    return result['content'][0]['text']
```

**ë¹„ìš©:**
- ~$0.05/í…ŒìŠ¤íŠ¸ (10ë‹¨ê³„)

#### Option C: OpenAI GPT-4 Vision
**ì¥ì :**
- ê°„ë‹¨í•œ API
- ë†’ì€ ì •í™•ë„

```python
from openai import OpenAI

client = OpenAI(api_key="your-key")

def analyze_screen_gpt4(image_path, question):
    with open(image_path, 'rb') as f:
        image_data = base64.b64encode(f.read()).decode()
    
    response = client.chat.completions.create(
        model="gpt-4-vision-preview",
        messages=[{
            "role": "user",
            "content": [
                {"type": "text", "text": question},
                {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{image_data}"}}
            ]
        }]
    )
    
    return response.choices[0].message.content
```

**ë¹„êµ ê²°ë¡ :**
- **ê°œë°œ/í…ŒìŠ¤íŠ¸**: Ollama + LLaVA (ë¬´ë£Œ, ë¹ ë¦„)
- **í”„ë¡œë•ì…˜**: Claude API (ì •í™•ë„)
- **í•˜ì´ë¸Œë¦¬ë“œ**: OCRë¡œ ë²„íŠ¼ ì°¾ê³ , LLMì€ ê²€ì¦ë§Œ

---

### 3. ìµœì  ì¡°í•© ì „ëµ

#### ì „ëµ A: ì™„ì „ ë¡œì»¬ (ë¹„ìš© $0)
```
PaddleOCR (ë²„íŠ¼ ê°ì§€) + Ollama LLaVA (ê²€ì¦)
```
- ë¹„ìš©: $0
- ì†ë„: ë¹ ë¦„ (GPU ì‚¬ìš© ì‹œ)
- ì •í™•ë„: ì¤‘ìƒ
- ì˜¤í”„ë¼ì¸: ê°€ëŠ¥

#### ì „ëµ B: í•˜ì´ë¸Œë¦¬ë“œ (ì¶”ì²œ)
```
PaddleOCR (ë²„íŠ¼ ê°ì§€) + Claude API (ì˜ì‚¬ê²°ì •ë§Œ)
```
- ë¹„ìš©: ~$0.01/í…ŒìŠ¤íŠ¸ (Claude í˜¸ì¶œ ìµœì†Œí™”)
- ì†ë„: ë¹ ë¦„
- ì •í™•ë„: ë†’ìŒ
- ì˜¤í”„ë¼ì¸: ë¶ˆê°€

#### ì „ëµ C: í’€ í´ë¼ìš°ë“œ
```
AWS Rekognition + Claude API
```
- ë¹„ìš©: ~$0.065/í…ŒìŠ¤íŠ¸
- ì†ë„: ì¤‘ê°„ (ë„¤íŠ¸ì›Œí¬ ì§€ì—°)
- ì •í™•ë„: ìµœê³ 
- ì˜¤í”„ë¼ì¸: ë¶ˆê°€

**ì¶”ì²œ:** ì „ëµ B (í•˜ì´ë¸Œë¦¬ë“œ)
- Phase 1 (í•™ìŠµ): PaddleOCR + Claude API
- Phase 2 (ì‹¤í–‰): PaddleOCRë§Œ (ì¢Œí‘œ ê¸°ë°˜)

---

## UI ì¸í„°í˜ì´ìŠ¤ ì„ íƒ

### Option A: Streamlit (ì¶”ì²œ)
**ì¥ì :**
- ë¹ ë¥¸ ê°œë°œ
- ì›¹ ê¸°ë°˜ (ë¸Œë¼ìš°ì €ì—ì„œ ì‹¤í–‰)
- ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
- ì´ë¯¸ì§€/ì°¨íŠ¸ í‘œì‹œ ìš©ì´

**ì„¤ì¹˜:**
```bash
pip install streamlit
```

**ì˜ˆì‹œ:**
```python
import streamlit as st
import pyautogui

st.title("ğŸ® Unreal ê²Œì„ QA ìë™í™”")

# ì‚¬ìš©ì ì…ë ¥
test_scenario = st.text_area("í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ì…ë ¥", 
    "ê²Œì„ ì‹¤í–‰ â†’ ë¡œê·¸ì¸ â†’ ë©”ì¸ ë©”ë‰´ í™•ì¸")

if st.button("í…ŒìŠ¤íŠ¸ ì‹œì‘"):
    with st.spinner("í…ŒìŠ¤íŠ¸ ì§„í–‰ ì¤‘..."):
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        screenshot = pyautogui.screenshot()
        st.image(screenshot, caption="í˜„ì¬ í™”ë©´")
        
        # OCR ê²°ê³¼
        st.write("ê°ì§€ëœ ë²„íŠ¼:", detected_buttons)

# ì‹¤í–‰
# streamlit run qa_automation.py
```

### Option B: Gradio
**ì¥ì :**
- Streamlitë³´ë‹¤ ê°„ë‹¨
- ìë™ API ìƒì„±
- ê³µìœ  ë§í¬ ìƒì„± ê°€ëŠ¥

```python
import gradio as gr

def run_test(scenario):
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    return "í…ŒìŠ¤íŠ¸ ì™„ë£Œ", screenshot

demo = gr.Interface(
    fn=run_test,
    inputs=gr.Textbox(label="í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤"),
    outputs=[gr.Textbox(label="ê²°ê³¼"), gr.Image(label="ìŠ¤í¬ë¦°ìƒ·")]
)

demo.launch()
```

### Option C: Jupyter Notebook
**ì¥ì :**
- ì¸í„°ë™í‹°ë¸Œ ê°œë°œ
- ë‹¨ê³„ë³„ ì‹¤í–‰
- ì‹œê°í™” ìš©ì´

**ì¶”ì²œ:** Streamlit (í”„ë¡œë•ì…˜) + Jupyter (ê°œë°œ)

---

## êµ¬í˜„ ì•„í‚¤í…ì²˜

### ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ êµ¬ì¡°

```python
# qa_automation_ide.py
import pyautogui
from paddleocr import PaddleOCR
import ollama  # ë˜ëŠ” boto3 for Claude
import streamlit as st
import time

class GameQAAutomation:
    def __init__(self, use_local_llm=True):
        # OCR ì´ˆê¸°í™”
        self.ocr = PaddleOCR(use_angle_cls=True, lang='en')
        
        # LLM ì„ íƒ
        self.use_local_llm = use_local_llm
        if not use_local_llm:
            import boto3
            self.bedrock = boto3.client('bedrock-runtime', 
                                       region_name='ap-northeast-2')
    
    def capture_and_analyze(self):
        """í™”ë©´ ìº¡ì²˜ ë° ë¶„ì„"""
        # 1. ìŠ¤í¬ë¦°ìƒ·
        screenshot = pyautogui.screenshot()
        screenshot.save('temp.png')
        
        # 2. OCRë¡œ ë²„íŠ¼ ê°ì§€
        buttons = self.detect_buttons('temp.png')
        
        # 3. LLMìœ¼ë¡œ ë‹¤ìŒ ì•¡ì…˜ ê²°ì •
        action = self.decide_action('temp.png', buttons)
        
        return buttons, action
    
    def detect_buttons(self, image_path):
        """PaddleOCRë¡œ ë²„íŠ¼ ê°ì§€"""
        result = self.ocr.ocr(image_path, cls=True)
        
        buttons = []
        for line in result[0]:
            bbox = line[0]
            text = line[1][0]
            confidence = line[1][1]
            
            # ì¤‘ì‹¬ì  ê³„ì‚°
            center_x = sum([p[0] for p in bbox]) / 4
            center_y = sum([p[1] for p in bbox]) / 4
            
            buttons.append({
                'text': text,
                'x': int(center_x),
                'y': int(center_y),
                'confidence': confidence
            })
        
        return buttons
    
    def decide_action(self, image_path, buttons, goal):
        """LLMìœ¼ë¡œ ë‹¤ìŒ ì•¡ì…˜ ê²°ì •"""
        
        if self.use_local_llm:
            # Ollama LLaVA ì‚¬ìš©
            response = ollama.chat(
                model='llava:13b',
                messages=[{
                    'role': 'user',
                    'content': f"ëª©í‘œ: {goal}\nê°ì§€ëœ ë²„íŠ¼: {buttons}\nì–´ë–¤ ë²„íŠ¼ì„ í´ë¦­í•´ì•¼ í•˜ë‚˜ìš”?",
                    'images': [image_path]
                }]
            )
            return response['message']['content']
        else:
            # Claude API ì‚¬ìš© (ìœ„ ì„¹ì…˜ ì°¸ì¡°)
            pass
    
    def click_button(self, button):
        """ë²„íŠ¼ í´ë¦­"""
        pyautogui.click(button['x'], button['y'])
        time.sleep(2)
```

---

## Bedrock Agent í™œìš© ë°©ì•ˆ

### Bedrock Agentë€?

AWS Bedrock AgentëŠ” ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ ìë™í™”í•˜ëŠ” AI ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.

**êµ¬ì„± ìš”ì†Œ:**
1. **Foundation Model**: Claude ë“±
2. **Action Groups**: Lambda í•¨ìˆ˜ë¡œ ì‹¤ì œ ì‘ì—… ìˆ˜í–‰
3. **Knowledge Base**: ê²Œì„ UI íŒ¨í„´ í•™ìŠµ
4. **Orchestration**: ìë™ ì›Œí¬í”Œë¡œìš° ê´€ë¦¬

### ê²Œì„ QA Agent ì„¤ê³„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Bedrock Agent (QA Orchestrator)    â”‚
â”‚  - ìì—°ì–´ ëª…ë ¹ í•´ì„                      â”‚
â”‚  - í…ŒìŠ¤íŠ¸ ë‹¨ê³„ ë¶„í•´                      â”‚
â”‚  - ê²°ê³¼ ê²€ì¦                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â†“                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Action  â”‚      â”‚  Knowledge   â”‚
â”‚ Groups  â”‚      â”‚    Base      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“                   â†“
Lambda Functions    ê²Œì„ UI íŒ¨í„´
- ê²Œì„ ì‹¤í–‰         - ë¡œê·¸ì¸ í™”ë©´
- ìŠ¤í¬ë¦°ìƒ· ìº¡ì²˜     - ë©”ì¸ ë©”ë‰´
- ë²„íŠ¼ í´ë¦­         - ì„¤ì • í™”ë©´
- OCR ì‹¤í–‰          - ì—ëŸ¬ íŒ¨í„´
```

### Bedrock Agentì˜ ì¥ì 

1. **ìë™ ì›Œí¬í”Œë¡œìš°**: ë³µì¡í•œ ë‹¨ê³„ë¥¼ ìë™ìœ¼ë¡œ ê´€ë¦¬
2. **ì»¨í…ìŠ¤íŠ¸ ìœ ì§€**: ì´ì „ ë‹¨ê³„ ê¸°ì–µ
3. **ì—ëŸ¬ ì²˜ë¦¬**: ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ ë˜ëŠ” ëŒ€ì•ˆ ì œì‹œ
4. **í™•ì¥ì„±**: ìƒˆë¡œìš´ Action ì‰½ê²Œ ì¶”ê°€
5. **ê´€ë¦¬ ìš©ì´**: AWS ì½˜ì†”ì—ì„œ ëª¨ë‹ˆí„°ë§

### Bedrock Agent vs ì§ì ‘ êµ¬í˜„

| í•­ëª© | Bedrock Agent | ì§ì ‘ êµ¬í˜„ (IDE) |
|------|---------------|----------------|
| ê°œë°œ ì‹œê°„ | ì§§ìŒ (ì„¤ì •ë§Œ) | ê¸¸ìŒ (ì½”ë“œ ì‘ì„±) |
| ìœ ì§€ë³´ìˆ˜ | ì‰¬ì›€ | ì–´ë ¤ì›€ |
| ë¹„ìš© | ì¤‘ê°„ ($0.01/ìš”ì²­) | ë‚®ìŒ (ë¡œì»¬ OCR) |
| ìœ ì—°ì„± | ì¤‘ê°„ | ë†’ìŒ |
| ì˜¤í”„ë¼ì¸ | ë¶ˆê°€ | ê°€ëŠ¥ (ë¡œì»¬ LLM) |
| ë””ë²„ê¹… | ì–´ë ¤ì›€ | ì‰¬ì›€ (IDE) |

**ì¶”ì²œ:**
- **í”„ë¡œí† íƒ€ì…/ê°œë°œ**: ì§ì ‘ êµ¬í˜„ (ë¡œì»¬ OCR + LLM)
- **í”„ë¡œë•ì…˜/ëŒ€ê·œëª¨**: Bedrock Agent (ê´€ë¦¬ ìš©ì´)
- **í•˜ì´ë¸Œë¦¬ë“œ**: IDEì—ì„œ ê°œë°œ â†’ Agentë¡œ ë°°í¬

---

## ì‹¤í–‰ í™˜ê²½ ì„¤ì •

### 1. Python í™˜ê²½ ì„¤ì •

```bash
# ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv venv
venv\Scripts\activate

# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install pyautogui paddleocr paddlepaddle streamlit

# ì„ íƒì  íŒ¨í‚¤ì§€
pip install ollama-python  # ë¡œì»¬ LLM
pip install boto3          # AWS Bedrock
pip install easyocr        # ëŒ€ì²´ OCR
```

### 2. Ollama ì„¤ì • (ë¡œì»¬ LLM ì‚¬ìš© ì‹œ)

```bash
# Ollama ì„¤ì¹˜
# https://ollama.com/download

# LLaVA ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
ollama pull llava:13b

# í…ŒìŠ¤íŠ¸
ollama run llava:13b
```

### 3. GPU ì„¤ì • (ì„ íƒì , ì„±ëŠ¥ í–¥ìƒ)

```bash
# CUDA í™•ì¸
nvidia-smi

# PaddlePaddle GPU ë²„ì „
pip uninstall paddlepaddle
pip install paddlepaddle-gpu

# PyTorch GPU (EasyOCRìš©)
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

### 4. í”„ë¡œì íŠ¸ êµ¬ì¡°

```
unreal-qa-automation/
â”œâ”€â”€ qa_automation_ide.py      # ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ streamlit_ui.py            # Streamlit UI
â”œâ”€â”€ ocr_engine.py              # OCR ë˜í¼
â”œâ”€â”€ llm_engine.py              # LLM ë˜í¼
â”œâ”€â”€ game_controller.py         # PyAutoGUI ì œì–´
â”œâ”€â”€ requirements.txt           # ì˜ì¡´ì„±
â”œâ”€â”€ config.yaml                # ì„¤ì • íŒŒì¼
â”œâ”€â”€ screenshots/               # ìŠ¤í¬ë¦°ìƒ· ì €ì¥
â”œâ”€â”€ test_scripts/              # ìƒì„±ëœ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ reports/                   # í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸
```

---

## ì‹¤í–‰ ê°€ì´ë“œ

### ë¹ ë¥¸ ì‹œì‘ (Streamlit UI)

```bash
# 1. í™˜ê²½ ì„¤ì •
python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt

# 2. Ollama ì„¤ì¹˜ ë° ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ì„ íƒì )
ollama pull llava:13b

# 3. Streamlit ì‹¤í–‰
streamlit run streamlit_ui.py
```

**ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:8501 ì ‘ì†**

### Jupyter Notebookìœ¼ë¡œ ê°œë°œ

```python
# qa_test.ipynb
import pyautogui
from paddleocr import PaddleOCR
import ollama

# OCR ì´ˆê¸°í™”
ocr = PaddleOCR(use_angle_cls=True, lang='en')

# 1. ìŠ¤í¬ë¦°ìƒ· ìº¡ì²˜
screenshot = pyautogui.screenshot()
screenshot.save('test.png')
display(screenshot)  # Jupyterì—ì„œ í‘œì‹œ

# 2. OCR ì‹¤í–‰
result = ocr.ocr('test.png', cls=True)
for line in result[0]:
    print(f"í…ìŠ¤íŠ¸: {line[1][0]}, ì‹ ë¢°ë„: {line[1][1]:.2f}")

# 3. LLM ë¶„ì„
response = ollama.chat(
    model='llava:13b',
    messages=[{
        'role': 'user',
        'content': 'ì´ í™”ë©´ì—ì„œ ë¡œê·¸ì¸ ë²„íŠ¼ì„ ì°¾ì•„ì£¼ì„¸ìš”',
        'images': ['test.png']
    }]
)
print(response['message']['content'])
```

### VS Codeì—ì„œ ë””ë²„ê¹…

```json
// .vscode/launch.json
{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "QA Automation",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/qa_automation_ide.py",
            "console": "integratedTerminal",
            "args": ["--mode", "learn", "--test-name", "login_test"]
        }
    ]
}
```

---

## ë¹„ìš© ë¹„êµ

### ì‹œë‚˜ë¦¬ì˜¤: ì›” 1,000íšŒ í…ŒìŠ¤íŠ¸ (ê° 10ë‹¨ê³„)

| êµ¬ì„± | OCR | LLM | ì›” ë¹„ìš© | ì†ë„ |
|------|-----|-----|---------|------|
| **ì™„ì „ ë¡œì»¬** | PaddleOCR | Ollama LLaVA | $0 | ë¹ ë¦„ (GPU) |
| **í•˜ì´ë¸Œë¦¬ë“œ** | PaddleOCR | Claude API | ~$10 | ë¹ ë¦„ |
| **í’€ í´ë¼ìš°ë“œ** | Rekognition | Claude API | ~$65 | ì¤‘ê°„ |

**ì¶”ì²œ:** í•˜ì´ë¸Œë¦¬ë“œ (PaddleOCR + Claude API)
- ë¹„ìš© íš¨ìœ¨ì 
- ë†’ì€ ì •í™•ë„
- ë¹ ë¥¸ ì†ë„

---

## ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

### OCR ì„±ëŠ¥ (1920x1080 ìŠ¤í¬ë¦°ìƒ·)

| ì—”ì§„ | CPU | GPU (RTX 3060) | ì •í™•ë„ |
|------|-----|----------------|--------|
| PaddleOCR | 0.8ì´ˆ | 0.15ì´ˆ | 95% |
| EasyOCR | 1.5ì´ˆ | 0.3ì´ˆ | 93% |
| Rekognition | 0.5ì´ˆ (ë„¤íŠ¸ì›Œí¬ í¬í•¨) | - | 97% |

### LLM ì„±ëŠ¥ (ì´ë¯¸ì§€ ë¶„ì„)

| ëª¨ë¸ | ì‘ë‹µ ì‹œê°„ | ì •í™•ë„ | ë¹„ìš©/ìš”ì²­ |
|------|-----------|--------|-----------|
| Ollama LLaVA 13B (GPU) | 2-3ì´ˆ | 85% | $0 |
| Ollama LLaVA 7B (GPU) | 1-2ì´ˆ | 80% | $0 |
| Claude 3.5 Sonnet | 1-2ì´ˆ | 95% | $0.01 |
| GPT-4 Vision | 2-3ì´ˆ | 95% | $0.02 |

---

## í•œê³„ ë° í•´ê²° ë°©ì•ˆ

### í•œê³„ì 

1. **ë™ì  UI ìœ„ì¹˜ ë³€í™”**
   - í•´ê²°: ë§¤ë²ˆ OCRë¡œ ì¬íƒì§€

2. **3D ê²Œì„ í™”ë©´ (í…ìŠ¤íŠ¸ ì—†ìŒ)**
   - í•´ê²°: í…œí”Œë¦¿ ë§¤ì¹­ ë˜ëŠ” Custom Vision ëª¨ë¸

3. **ë„¤íŠ¸ì›Œí¬ ê²Œì„ (ì§€ì—°)**
   - í•´ê²°: ëŒ€ê¸° ì‹œê°„ ë™ì  ì¡°ì •

4. **ë¡œì»¬ LLM ì •í™•ë„**
   - í•´ê²°: ì¤‘ìš”í•œ ë‹¨ê³„ë§Œ Claude API ì‚¬ìš©

### ê³ ê¸‰ ê¸°ëŠ¥ í™•ì¥

1. **í…œí”Œë¦¿ ë§¤ì¹­** (í…ìŠ¤íŠ¸ ì—†ëŠ” ë²„íŠ¼)
```python
import cv2

template = cv2.imread('button_template.png')
screenshot = cv2.imread('screenshot.png')
result = cv2.matchTemplate(screenshot, template, cv2.TM_CCOEFF_NORMED)
min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)
```

2. **ë¹„ë””ì˜¤ ë…¹í™”**
```python
import cv2
import numpy as np

fourcc = cv2.VideoWriter_fourcc(*'XVID')
out = cv2.VideoWriter('test.avi', fourcc, 20.0, (1920, 1080))

while testing:
    screenshot = pyautogui.screenshot()
    frame = np.array(screenshot)
    out.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))
```

3. **ë©€í‹° í•´ìƒë„ ì§€ì›**
```python
def scale_coordinates(x, y, from_res=(1920, 1080), to_res=None):
    if to_res is None:
        to_res = pyautogui.size()
    
    scale_x = to_res[0] / from_res[0]
    scale_y = to_res[1] / from_res[1]
    
    return int(x * scale_x), int(y * scale_y)
```

---

## ê²°ë¡ 

### Windows IDE í™˜ê²½ì˜ ì¥ì 

âœ… **ë‹¨ìˆœì„±**: WSL ê²½ìœ  ì—†ì´ ì§ì ‘ ì‹¤í–‰
âœ… **ë¹„ìš© ì ˆê°**: ë¡œì»¬ OCRë¡œ API ë¹„ìš© ìµœì†Œí™”
âœ… **ì†ë„**: ë„¤íŠ¸ì›Œí¬ ì§€ì—° ì—†ìŒ
âœ… **ë””ë²„ê¹…**: IDEì—ì„œ ì§ì ‘ ë””ë²„ê¹…
âœ… **ì˜¤í”„ë¼ì¸**: ë¡œì»¬ LLM ì‚¬ìš© ì‹œ ê°€ëŠ¥

### ì¶”ì²œ êµ¬ì„±

**ê°œë°œ/í”„ë¡œí† íƒ€ì…:**
- IDE: VS Code + Jupyter Notebook
- OCR: PaddleOCR (GPU)
- LLM: Ollama LLaVA 13B
- UI: Jupyter Notebook (ì¸í„°ë™í‹°ë¸Œ)
- ë¹„ìš©: $0

**í”„ë¡œë•ì…˜:**
- IDE: VS Code
- OCR: PaddleOCR (GPU)
- LLM: Claude API (ì¤‘ìš” ë‹¨ê³„ë§Œ)
- UI: Streamlit (ì›¹ ì¸í„°í˜ì´ìŠ¤)
- ë¹„ìš©: ~$10/ì›” (1,000íšŒ í…ŒìŠ¤íŠ¸)

**ì—”í„°í”„ë¼ì´ì¦ˆ:**
- Bedrock Agent (ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜)
- Lambda (Action Groups)
- Knowledge Base (UI íŒ¨í„´)
- ë¹„ìš©: ~$10-20/ì›”
- ê´€ë¦¬: AWS ì½˜ì†”

### ë‹¤ìŒ ë‹¨ê³„

1. **í™˜ê²½ ì„¤ì •** (30ë¶„)
   - Python ê°€ìƒí™˜ê²½
   - PaddleOCR ì„¤ì¹˜
   - Ollama ì„¤ì¹˜ (ì„ íƒì )

2. **í”„ë¡œí† íƒ€ì… ê°œë°œ** (2-3ì‹œê°„)
   - Jupyter Notebookìœ¼ë¡œ ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
   - OCR + LLM í†µí•©

3. **Streamlit UI ê°œë°œ** (1-2ì¼)
   - ì›¹ ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„
   - í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ì…ë ¥
   - ì‹¤ì‹œê°„ ê²°ê³¼ í‘œì‹œ

4. **í…ŒìŠ¤íŠ¸ ë° ìµœì í™”** (1-2ì¼)
   - ì‹¤ì œ ê²Œì„ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
   - ì„±ëŠ¥ ìµœì í™”
   - ì—ëŸ¬ ì²˜ë¦¬

5. **ë°°í¬** (ì„ íƒì )
   - Bedrock Agentë¡œ ì „í™˜
   - CI/CD í†µí•©

**ì˜ˆìƒ ê°œë°œ ì‹œê°„: 3-5ì¼**
